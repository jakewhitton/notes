# Independence

We say two events are "independent" iff

$$P(A \cap B) = P(A) \cdot P(B)$$

We can also do

$$P(B \cap A) = P(A) \cdot P(B)$$
$$P(B) \cdot P(A \vert B) = P(A) \cdot P(B)$$
$$P(A \vert B) = P(A)$$

This is useful, because that equality can make the evaluation of probabilities
easier.

## Independence of Two Events in Conditional Universes

We say that two events are "conditionally independent given C" iff

$$P(A \cap B \vert C) = P(A \vert C) \cdot P(B \vert C)$$

Interestingly, the independence of $A$ and $B$ universally does not imply the
conditional independence of $A$ and $B$ given $C$, and nor does the reverse.

## Independence of Several Events in Conditional Universes

The principle we want to preserve is that, given some set $S$ of independent
events, we want information provided about the status of any of those events
should not change the probabilities of any of the other events in the set.

You can extend the earlier concept to **pairwise independence**, where each
individual pair of events is independent to each other.

However, you must also establish that

$$\forall M \subset S, P\bigg(\bigcap\limits_{E \in M} E\bigg) = \prod\limits_{E \in M} P(E)$$
